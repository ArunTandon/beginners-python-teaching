{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politcs and Social Sciences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to analyze the text from any wikipedia page. The code below connects with wikipedia, imports the text found on the page and prepares it for further analysis. By default it uses the wikipedia page about Donald Trump but you are free to use any other page, just change the link used in the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Specify url of the web page\n",
    "source = urlopen('https://en.wikipedia.org/wiki/Donald_Trump').read()\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "# Extract the plain text content from paragraphs\n",
    "text = ''\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text\n",
    "\n",
    "# Clean text\n",
    "text = re.sub(r'\\[.*?\\]+', '', text)\n",
    "text = text.replace('\\n', ' ')\n",
    "text = text.replace('\\xa0', '')\n",
    "text = text.replace('\\'s', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print first 1000 characters of `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Donald John Trump (born June 14, 1946) is an American politician who was the 45th president of the United States from 2017 to 2021. Before entering politics, he was a businessman and television personality. Born and raised in Queens, New York City, Trump attended Fordham University for two years and received a bachelor degree in economics from the Wharton School of the University of Pennsylvania. He became the president of his father Fred Trump real estate business in 1971, which he renamed The Trump Organization; he expanded the company operations to building and renovating skyscrapers, hotels, casinos, and golf courses. Trump later started various side ventures, mostly by licensing his name. Trump and his businesses have been involved in more than 4,000 state and federal legal actions, including six bankruptcies. He owned the Miss Universe brand of beauty pageants from 1996 to 2015, and produced and hosted the reality television series The Apprentice from 2004 to 2015. Trump politic\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like now to split the text into a list of sentences. For that we will need a way of detecting the end of a sentence. We will assume that a dot, exclamation mark or question mark followed by a space is the indicator of the end of a sentence. Complete the function below which checks if `char` is an end of sentence marker (`\". \"`, `\"? \"` or `\"! \"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nFalse\n"
     ]
    }
   ],
   "source": [
    "def end_of_sentence(char):\n",
    "    return char == \". \" or char == \"! \" or char == \"? \"\n",
    "\n",
    "# these tests should return True, True, False if your code is correct\n",
    "print(end_of_sentence(\". \"))\n",
    "print(end_of_sentence(\"? \"))\n",
    "print(end_of_sentence(\"D.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function split_sentences takes as argument a text represented by a simple string. Within the function we define a variable `sentences_ls` in which we will store the individual sentences. We need to extract both the start position and the end position of each sentence, we define the variables `start` and `end` and set to 0.\n",
    "Next we iterate over the entire text. In each run of the while loop we look at two consecutive characters of the text. If these are the end of sentence markers we extract the relevant fragment of the text and append it to the list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \n",
    "    sentences_ls = []\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    while end < len(text):\n",
    "        char = text[end:end+2]\n",
    "        if end_of_sentence(char):\n",
    "            #extract the sentence\n",
    "            sentence = text[start:end+1].strip()\n",
    "            \n",
    "            #append the sentence to the list of sentences\n",
    "            sentences_ls.append(sentence)\n",
    "            \n",
    "            #update the starting value\n",
    "            start = end + 1\n",
    "            \n",
    "        end = end + 1\n",
    "        \n",
    "    return sentences_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the functionning of `split_sentences` on the first 1000 characters of `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Donald John Trump (born June 14, 1946) is an American politician who was the 45th president of the United States from 2017 to 2021.',\n",
       " 'Before entering politics, he was a businessman and television personality.',\n",
       " 'Born and raised in Queens, New York City, Trump attended Fordham University for two years and received a bachelor degree in economics from the Wharton School of the University of Pennsylvania.',\n",
       " 'He became the president of his father Fred Trump real estate business in 1971, which he renamed The Trump Organization; he expanded the company operations to building and renovating skyscrapers, hotels, casinos, and golf courses.',\n",
       " 'Trump later started various side ventures, mostly by licensing his name.',\n",
       " 'Trump and his businesses have been involved in more than 4,000 state and federal legal actions, including six bankruptcies.',\n",
       " 'He owned the Miss Universe brand of beauty pageants from 1996 to 2015, and produced and hosted the reality television series The Apprentice from 2004 to 2015.']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "split_sentences(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the function works correctly define a new variable called `sentences_ls` and assign to it the result of calling the function `split_sentences` on the whole `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_ls = split_sentences(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tokenize` preprocesses a plain string to remove any punctuation and splits it into the list of lower case words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence).lower()\n",
    "    words = sentence.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the functionning of `tokenize` on the first element of `sentences_ls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['donald',\n",
       " 'john',\n",
       " 'trump',\n",
       " 'born',\n",
       " 'june',\n",
       " '14',\n",
       " '1946',\n",
       " 'is',\n",
       " 'an',\n",
       " 'american',\n",
       " 'politician',\n",
       " 'who',\n",
       " 'was',\n",
       " 'the',\n",
       " '45th',\n",
       " 'president',\n",
       " 'of',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'from',\n",
       " '2017',\n",
       " 'to',\n",
       " '2021']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "tokenize(sentences_ls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Text Statistics\n",
    "\n",
    "We would now like to make some basic statistics about our text. In particulat we would like to get the following information:\n",
    " - Total number of words in the text\n",
    " - Total number of sentences in the text\n",
    " - Number of words in shortest sentence\n",
    " - Number of words in longest sentence\n",
    " - Average number of words in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To get these values we need to find out what is the number of words in every sentence. Define an empty list called. `length_of_sentences`. Inside the `for` loop (we will learn about for loops later during the course) write one line of code which will append the length of `sentence` to the `length_of_sentences` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_sentences = []\n",
    "for sentence in sentences_ls:\n",
    "    #append the length of sentence to the list\n",
    "    length_of_sentences.append(len(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a variable called `words_ls` and assign to it the result of calling the `tokenize` function on the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ls = tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients to generate the statistics about our text. Print them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of words in the text: 17495\nTotal numer of sentences in the text: 792\nNumber of words in shortest sentence: 4\nNumber of words in longest sentence: 822\nAverage number of words in a sentence: 22.089646464646464\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words in the text:\", len(words_ls))\n",
    "print(\"Total numer of sentences in the text:\", len(sentences_ls))\n",
    "print(\"Number of words in shortest sentence:\", min(length_of_sentences))\n",
    "print(\"Number of words in longest sentence:\", max(length_of_sentences))\n",
    "print(\"Average number of words in a sentence:\", len(words_ls)/len(length_of_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the number of words in shortest sentence is only 4. This seems a little bit suspicious. We would like to investigate this sentence. Write code which will print only the sentences whose length is smaller than 5.  \n",
    "**HINT 1:** Use the `while` loop and a dummy variable `i` which will represent the current index in the `length_of_sentences` list. Set this variable `i` initially to 0 and with each iteration of the while loop increase it by one.  \n",
    "**HINT 2:** What is the condition for your loop to end? `i` certainly cannot be larger than the the length of the `length_of_sentences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "U.S.\nU.S.\naid.\nSen.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(sentences_ls):\n",
    "    if length_of_sentences[i] == 4:\n",
    "        print(sentences_ls[i])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average people read around 220 words per minute. Using this information we can compute the estimated reading time of an article from the formula:\n",
    "$$\\textrm{reading time}= \\dfrac{\\textrm{number of words in text}}{\\textrm{number of words per minute}}$$\n",
    "Complete the function below to return the reading time (rounded to 2 decimal places)given a list of words from the text as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_time(words_ls):\n",
    "    total_words = len(words_ls)\n",
    "    reading_time = round(total_words / 220, 2)\n",
    "    return reading_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the user for input: How much time do they have to read a text? Based on that information print if they are able to read the text in this time. How much will it take them to read the whole text. How many more spare minutes they will have or what percentage of the text will they be able to read given their time constraint.  \n",
    "Remember, when asking for the user input remember to check the validity of the input (use the `while` loop for that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You can read the whole article. It will take you 79.52 minutes and you will have 20.48 minutes left.\n"
     ]
    }
   ],
   "source": [
    "time = -1\n",
    "while time < 0:\n",
    "    time = int(input(\"How many minutes do you have? \"))\n",
    "\n",
    "time_to_read = reading_time(words_ls)\n",
    "\n",
    "if time < time_to_read:\n",
    "    print(\"You don't have enough time to read this text. It takes\", time_to_read, \"minutes to read the entire text.\", \n",
    "          \"\\r\\nYou will only manage to read\", round((time/time_to_read)*100,2), \"% of the text\")\n",
    "else:\n",
    "    print(\"You can read the whole article. It will take you\", time_to_read, \"minutes and you will have\", \n",
    "          round(time - time_to_read,2), \"minutes left.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we would like to investigate is to find the most popular words in the entire text. To do this we will make use of a built-in module Counter. The code below assigns to the `word_rank` a list of tuples `(str, count of str)` which is sorted by the most common words in word_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_rank = Counter(words_ls).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 20 words in word_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('the', 1061), ('trump', 597), ('in', 566), ('and', 529), ('of', 503), ('to', 435), ('a', 324), ('his', 223), ('he', 171), ('that', 168), ('for', 160), ('was', 153), ('as', 141), ('on', 128), ('by', 119), ('with', 114), ('from', 102), ('had', 81), ('were', 80), ('us', 73)]\n"
     ]
    }
   ],
   "source": [
    "print(word_rank[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the user for a word and print whether this word is present in the text. If it is, print additionally the count  of this word in the text. Remember to transform the user input to lower case before checking if it is present in the word_rank.  \n",
    "**HINT 1**: Use the same strategy as before for iterating over the `word_rank` list using the `while` loop.  \n",
    "**HINT 2**: Create a boolean dummy variable `flag` which at the beginning will be set to `False`. If inside the loop, the word you are searching for appeares, change the value of `flag` to `True`. After iterating over the entire `word_rank` list, check the value of `flag`. Based on that conclude if the word you were searching for is present in the list or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This word appeared in the text:  597 times\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Give a word: \").lower()\n",
    "i = 0\n",
    "flag = False #dummy variable to track the existance of the word\n",
    "\n",
    "while i < len(word_rank):\n",
    "    if word_rank[i][0] == word:\n",
    "        print(\"This word appeared in the text: \", word_rank[i][1], \"times\")\n",
    "        flag = True\n",
    "    i = i + 1\n",
    "    \n",
    "if flag == False:\n",
    "    print(\"This word is not present in the text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}