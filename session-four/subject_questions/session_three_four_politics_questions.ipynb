{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politcs and Social Sciences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to analyze the text from any wikipedia page. The code below connects with wikipedia, imports the text found on the page and prepares it for further analysis. By default it uses the wikipedia page about Donald Trump but you are free to use any other page, just change the link used in the code. \n",
    "In this notebook whatch out for `[--TO DO--]` strings inside the code. These indicate the places where you should complete the pieces of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'source' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-973682b54a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Specify url of the web page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://en.wikipedia.org/wiki/Donald_Trump'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Extract the plain text content from paragraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'source' is not defined"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Specify url of the web page\n",
    "urlopen('https://en.wikipedia.org/wiki/Donald_Trump').read()\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "# Extract the plain text content from paragraphs\n",
    "text = ''\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text\n",
    "\n",
    "# Clean text\n",
    "text = re.sub(r'\\[.*?\\]+', '', text)\n",
    "text = text.replace('\\n', ' ')\n",
    "text = text.replace('\\xa0', '')\n",
    "text = text.replace('\\'s', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print first 1000 characters of `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like now to split the text into a list of sentences. For that we will need a way of detecting the end of a sentence. We will assume that a dot, exclamation mark or question mark followed by a space is the indicator of the end of a sentence. Complete the function below which checks if `char` is an end of sentence marker (`\". \"`, `\"? \"` or `\"! \"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_of_sentence(char):\n",
    "    return \"[--TO DO: LOGICAL EXPRESSION --]\"\n",
    "\n",
    "# these tests should return True, True, False if your code is correct\n",
    "print(end_of_sentence(\". \"))\n",
    "print(end_of_sentence(\"? \"))\n",
    "print(end_of_sentence(\"D.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `split_sentences` takes as argument a text represented by a simple string. Within the function we define a variable `sentences_ls` in which we will store the individual sentences. We need to extract both the start position and the end position of each sentence, we define the variables `start` and `end` and set them 0.\n",
    "Next, we iterate over the entire text. In each run of the while loop we look at two consecutive characters of the text. If these are the end of sentence markers we extract the relevant fragment of the text and append it to the list of sentences. What is the condition to end the while loop? Can the `end` pointer be bigger than the total length of the text? Complete the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \n",
    "    #define the empty list for sentences\n",
    "    \"[--TO DO--]\"\n",
    "    \n",
    "    #set the start and end to 0\n",
    "    \"[--TO DO--]\"\n",
    "    \n",
    "    while \"[-- TO DO: logical expression for the while loop to terminate--]\":\n",
    "        char = text[end:end+2]\n",
    "        if end_of_sentence(char):\n",
    "            #extract the sentence\n",
    "            sentence = text[start:end+1].strip()\n",
    "            \n",
    "            #append the sentence to the list of sentences\n",
    "            \"[--TO DO--]\"\n",
    "            \n",
    "            #update the start pointer\n",
    "            start = end + 1\n",
    "        \n",
    "        #increase the end pointer by one\n",
    "        end = end + 1\n",
    "        \n",
    "    return sentences_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the functionning of `split_sentences` on the first 1000 characters of `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the function works correctly define a new variable called `sentences_ls` and assign to it the result of calling the function `split_sentences` on the whole `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tokenize` preprocesses a plain string to remove any punctuation and splits it into the list of lower case words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence).lower()\n",
    "    words = sentence.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the functionning of `tokenize` on the first element of `sentences_ls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Text Statistics\n",
    "\n",
    "We would now like to make some basic statistics about our text. In particulat we would like to get the following information:\n",
    " - Total number of words in the text\n",
    " - Total number of sentences in the text\n",
    " - Number of words in shortest sentence\n",
    " - Number of words in longest sentence\n",
    " - Average number of words in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To get these values we need to find out what is the number of words in every sentence. Define an empty list called. `length_of_sentences`. Inside the `for` loop (we will learn about for loops later during the course) write one line of code which will append the length of `sentence` to the `length_of_sentences` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_sentences = []\n",
    "for sentence in sentences_ls:\n",
    "    #append the length of sentence to the list\n",
    "    \"[--TO DO--]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a variable called `words_ls` and assign to it the result of calling the `tokenize` function on the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients to generate the statistics about our text. Print them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the number of words in shortest sentence is only 4. This seems a little bit suspicious. We would like to investigate this sentence. Write code which will print only the sentences whose length is smaller than 5.  \n",
    "**HINT 1:** Use the `while` loop and a dummy variable `i` which will represent the current index in the `length_of_sentences` list. Set this variable `i` initially to 0 and with each iteration of the while loop increase it by one.  \n",
    "**HINT 2:** What is the condition for your loop to end? `i` certainly cannot be larger than the the length of the `length_of_sentences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average people read around 220 words per minute. Using this information we can compute the estimated reading time of an article from the formula:\n",
    "$$\\textrm{reading time}= \\dfrac{\\textrm{number of words in text}}{\\textrm{number of words per minute}}$$\n",
    "Complete the function below to return the reading time (rounded to 2 decimal places)given a list of words from the text as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_time(words_ls):\n",
    "    total_words = \"[--TO DO--]\"\n",
    "    reading_time = \"[--TO DO--]\"\n",
    "    return reading_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the user for input: How much time do they have to read a text? Based on that information print if they are able to read the text in this time. How much will it take them to read the whole text. How many more spare minutes they will have or what percentage of the text will they be able to read given their time constraint.  \n",
    "Remember, when asking for the user input remember to check the validity of the input (use the `while` loop for that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we would like to investigate is to find the most popular words in the entire text. To do this we will make use of a built-in module Counter. The code below assigns to the `word_rank` a list of tuples `(str, count of str)` which is sorted by the most common words in word_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_rank = Counter(words_ls).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 20 words in word_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the user for a word and print whether this word is present in the text. If it is, print additionally the count  of this word in the text. Remember to transform the user input to lower case before checking if it is present in the word_rank.  \n",
    "**HINT 1**: Use the same strategy as before for iterating over the `word_rank` list using the `while` loop.  \n",
    "**HINT 2**: Create a boolean dummy variable `flag` which at the beginning will be set to `False`. If inside the loop, the word you are searching for appeares, change the value of `flag` to `True`. After iterating over the entire `word_rank` list, check the value of `flag`. Based on that conclude if the word you were searching for is present in the list or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}